{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.models import load_model\n",
    "import keras\n",
    "from sklearn import preprocessing\n",
    "import tensorflow as tf\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 22.  28.]\n",
      " [ 49.  64.]]\n"
     ]
    }
   ],
   "source": [
    "# Creates a graph.\n",
    "a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3], name='a')\n",
    "b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name='b')\n",
    "c = tf.matmul(a, b)\n",
    "# Creates a session with log_device_placement set to True.\n",
    "sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\n",
    "# Runs the op.\n",
    "print(sess.run(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(layers):\n",
    "    d = 0.3\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(LSTM(256, input_shape=(layers[1], layers[0]), return_sequences=True))\n",
    "    model.add(Dropout(d))\n",
    "        \n",
    "    model.add(LSTM(256, input_shape=(layers[1], layers[0]), return_sequences=False))\n",
    "    model.add(Dropout(d))\n",
    "        \n",
    "    model.add(Dense(32,kernel_initializer=\"uniform\",activation='relu'))        \n",
    "    model.add(Dense(1,kernel_initializer=\"uniform\",activation='linear'))\n",
    "    \n",
    "    # adam = keras.optimizers.Adam(decay=0.2)\n",
    "        \n",
    "    start = time.time()\n",
    "    model.compile(loss='mse',optimizer='adam', metrics=['accuracy'])\n",
    "    print(\"Compilation Time : \", time.time() - start)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pandas.read_csv(\"../nyse/prices-split-adjusted.csv\",index_col = 0)\n",
    "df = df[df.symbol == 'EBAY']\n",
    "df[\"adj close\"] = df.close # Moving close to the last column\n",
    "df.drop(['close'], 1, inplace=True) # Moving close to the last column\n",
    "df.drop(['symbol'],1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_data(df):\n",
    "    min_max_scaler = preprocessing.MinMaxScaler()\n",
    "    df['open'] = min_max_scaler.fit_transform(df.open.values.reshape(-1,1))\n",
    "    df['high'] = min_max_scaler.fit_transform(df.high.values.reshape(-1,1))\n",
    "    df['low'] = min_max_scaler.fit_transform(df.low.values.reshape(-1,1))\n",
    "    df['volume'] = min_max_scaler.fit_transform(df.volume.values.reshape(-1,1))\n",
    "    df['adj close'] = min_max_scaler.fit_transform(df['adj close'].values.reshape(-1,1))\n",
    "    return df\n",
    "df = normalize_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(stock, seq_len):\n",
    "    amount_of_features = len(stock.columns) # 5\n",
    "    data = stock.as_matrix() \n",
    "    sequence_length = seq_len + 1 # index starting from 0\n",
    "    result = []\n",
    "    \n",
    "    for index in range(len(data) - sequence_length): # maxmimum date = lastest date - sequence length\n",
    "        result.append(data[index: index + sequence_length]) # index : index + 22days\n",
    "    \n",
    "    result = np.array(result)\n",
    "    row = round(0.9 * result.shape[0]) # 90% split\n",
    "    train = result[:int(row), :] # 90% date, all features \n",
    "    \n",
    "    x_train = train[:, :-1] \n",
    "    y_train = train[:, -1][:,-1]\n",
    "    \n",
    "    x_test = result[int(row):, :-1] \n",
    "    y_test = result[int(row):, -1][:,-1]\n",
    "\n",
    "    x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], amount_of_features))\n",
    "    x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], amount_of_features))  \n",
    "\n",
    "    return [x_train, y_train, x_test, y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "window = 22\n",
    "X_train, y_train, X_test, y_test = load_data(df, window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Compilation Time : ', 0.02491903305053711)\n"
     ]
    }
   ],
   "source": [
    "model = build_model([5,window,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1408 samples, validate on 157 samples\n",
      "Epoch 1/90\n",
      "1408/1408 [==============================] - 2s - loss: 0.2125 - acc: 7.1023e-04 - val_loss: 0.4438 - val_acc: 0.0000e+00\n",
      "Epoch 2/90\n",
      "1408/1408 [==============================] - 0s - loss: 0.1482 - acc: 7.1023e-04 - val_loss: 0.1185 - val_acc: 0.0000e+00\n",
      "Epoch 3/90\n",
      "1408/1408 [==============================] - 0s - loss: 0.0375 - acc: 7.1023e-04 - val_loss: 0.0122 - val_acc: 0.0000e+00\n",
      "Epoch 4/90\n",
      "1408/1408 [==============================] - 0s - loss: 0.0502 - acc: 7.1023e-04 - val_loss: 0.0715 - val_acc: 0.0000e+00\n",
      "Epoch 5/90\n",
      "1408/1408 [==============================] - 0s - loss: 0.0305 - acc: 7.1023e-04 - val_loss: 0.1221 - val_acc: 0.0000e+00\n",
      "Epoch 6/90\n",
      "1408/1408 [==============================] - 0s - loss: 0.0332 - acc: 7.1023e-04 - val_loss: 0.0919 - val_acc: 0.0000e+00\n",
      "Epoch 7/90\n",
      "1408/1408 [==============================] - 0s - loss: 0.0171 - acc: 7.1023e-04 - val_loss: 0.0268 - val_acc: 0.0000e+00\n",
      "Epoch 8/90\n",
      "1408/1408 [==============================] - 0s - loss: 0.0092 - acc: 7.1023e-04 - val_loss: 0.0073 - val_acc: 0.0000e+00\n",
      "Epoch 9/90\n",
      "1408/1408 [==============================] - 0s - loss: 0.0054 - acc: 7.1023e-04 - val_loss: 0.0109 - val_acc: 0.0000e+00\n",
      "Epoch 10/90\n",
      "1408/1408 [==============================] - 0s - loss: 0.0077 - acc: 7.1023e-04 - val_loss: 0.0050 - val_acc: 0.0000e+00\n",
      "Epoch 11/90\n",
      "1408/1408 [==============================] - 0s - loss: 0.0060 - acc: 7.1023e-04 - val_loss: 0.0050 - val_acc: 0.0000e+00\n",
      "Epoch 12/90\n",
      "1408/1408 [==============================] - 0s - loss: 0.0037 - acc: 7.1023e-04 - val_loss: 0.0119 - val_acc: 0.0000e+00\n",
      "Epoch 13/90\n",
      "1408/1408 [==============================] - 0s - loss: 0.0033 - acc: 7.1023e-04 - val_loss: 0.0094 - val_acc: 0.0000e+00\n",
      "Epoch 14/90\n",
      "1408/1408 [==============================] - 0s - loss: 0.0029 - acc: 7.1023e-04 - val_loss: 0.0084 - val_acc: 0.0000e+00\n",
      "Epoch 15/90\n",
      "1408/1408 [==============================] - 0s - loss: 0.0031 - acc: 7.1023e-04 - val_loss: 0.0123 - val_acc: 0.0000e+00\n",
      "Epoch 16/90\n",
      "1408/1408 [==============================] - 0s - loss: 0.0028 - acc: 7.1023e-04 - val_loss: 0.0088 - val_acc: 0.0000e+00\n",
      "Epoch 17/90\n",
      "1408/1408 [==============================] - 0s - loss: 0.0021 - acc: 7.1023e-04 - val_loss: 0.0048 - val_acc: 0.0000e+00\n",
      "Epoch 18/90\n",
      "1408/1408 [==============================] - 0s - loss: 0.0021 - acc: 7.1023e-04 - val_loss: 0.0056 - val_acc: 0.0000e+00\n",
      "Epoch 19/90\n",
      "1408/1408 [==============================] - 0s - loss: 0.0020 - acc: 7.1023e-04 - val_loss: 0.0039 - val_acc: 0.0000e+00\n",
      "Epoch 20/90\n",
      "1408/1408 [==============================] - 0s - loss: 0.0020 - acc: 7.1023e-04 - val_loss: 0.0037 - val_acc: 0.0000e+00\n",
      "Epoch 21/90\n",
      "1408/1408 [==============================] - 0s - loss: 0.0018 - acc: 7.1023e-04 - val_loss: 0.0038 - val_acc: 0.0000e+00\n",
      "Epoch 22/90\n",
      "1408/1408 [==============================] - 0s - loss: 0.0017 - acc: 7.1023e-04 - val_loss: 0.0036 - val_acc: 0.0000e+00\n",
      "Epoch 23/90\n",
      "1408/1408 [==============================] - 0s - loss: 0.0016 - acc: 7.1023e-04 - val_loss: 0.0038 - val_acc: 0.0000e+00\n",
      "Epoch 24/90\n",
      "1408/1408 [==============================] - 0s - loss: 0.0017 - acc: 7.1023e-04 - val_loss: 0.0034 - val_acc: 0.0000e+00\n",
      "Epoch 25/90\n",
      "1408/1408 [==============================] - 0s - loss: 0.0016 - acc: 7.1023e-04 - val_loss: 0.0034 - val_acc: 0.0000e+00\n",
      "Epoch 26/90\n",
      "1408/1408 [==============================] - 0s - loss: 0.0016 - acc: 7.1023e-04 - val_loss: 0.0032 - val_acc: 0.0000e+00\n",
      "Epoch 27/90\n",
      "1408/1408 [==============================] - 0s - loss: 0.0016 - acc: 7.1023e-04 - val_loss: 0.0032 - val_acc: 0.0000e+00\n",
      "Epoch 28/90\n",
      "1408/1408 [==============================] - 0s - loss: 0.0016 - acc: 7.1023e-04 - val_loss: 0.0032 - val_acc: 0.0000e+00\n",
      "Epoch 29/90\n",
      "1408/1408 [==============================] - 0s - loss: 0.0016 - acc: 7.1023e-04 - val_loss: 0.0032 - val_acc: 0.0000e+00\n",
      "Epoch 30/90\n",
      "1408/1408 [==============================] - 0s - loss: 0.0015 - acc: 7.1023e-04 - val_loss: 0.0031 - val_acc: 0.0000e+00\n",
      "Epoch 31/90\n",
      "1408/1408 [==============================] - 0s - loss: 0.0015 - acc: 7.1023e-04 - val_loss: 0.0031 - val_acc: 0.0000e+00\n",
      "Epoch 32/90\n",
      "1408/1408 [==============================] - 0s - loss: 0.0016 - acc: 7.1023e-04 - val_loss: 0.0031 - val_acc: 0.0000e+00\n",
      "Epoch 33/90\n",
      "1408/1408 [==============================] - 0s - loss: 0.0015 - acc: 7.1023e-04 - val_loss: 0.0030 - val_acc: 0.0000e+00\n",
      "Epoch 34/90\n",
      "1408/1408 [==============================] - 0s - loss: 0.0014 - acc: 7.1023e-04 - val_loss: 0.0030 - val_acc: 0.0000e+00\n",
      "Epoch 35/90\n",
      "1408/1408 [==============================] - 0s - loss: 0.0014 - acc: 7.1023e-04 - val_loss: 0.0030 - val_acc: 0.0000e+00\n",
      "Epoch 36/90\n",
      "1408/1408 [==============================] - 0s - loss: 0.0015 - acc: 7.1023e-04 - val_loss: 0.0030 - val_acc: 0.0000e+00\n",
      "Epoch 37/90\n",
      "1408/1408 [==============================] - 0s - loss: 0.0016 - acc: 7.1023e-04 - val_loss: 0.0030 - val_acc: 0.0000e+00\n",
      "Epoch 38/90\n",
      "1408/1408 [==============================] - 0s - loss: 0.0015 - acc: 7.1023e-04 - val_loss: 0.0029 - val_acc: 0.0000e+00\n",
      "Epoch 39/90\n",
      "1408/1408 [==============================] - 0s - loss: 0.0014 - acc: 7.1023e-04 - val_loss: 0.0030 - val_acc: 0.0000e+00\n",
      "Epoch 40/90\n",
      "1408/1408 [==============================] - 0s - loss: 0.0015 - acc: 7.1023e-04 - val_loss: 0.0029 - val_acc: 0.0000e+00\n",
      "Epoch 41/90\n",
      "1408/1408 [==============================] - 0s - loss: 0.0015 - acc: 7.1023e-04 - val_loss: 0.0029 - val_acc: 0.0000e+00\n",
      "Epoch 42/90\n",
      "1408/1408 [==============================] - 0s - loss: 0.0014 - acc: 7.1023e-04 - val_loss: 0.0029 - val_acc: 0.0000e+00\n",
      "Epoch 43/90\n",
      "1408/1408 [==============================] - 0s - loss: 0.0015 - acc: 7.1023e-04 - val_loss: 0.0029 - val_acc: 0.0000e+00\n",
      "Epoch 44/90\n",
      "1408/1408 [==============================] - 0s - loss: 0.0014 - acc: 7.1023e-04 - val_loss: 0.0028 - val_acc: 0.0000e+00\n",
      "Epoch 45/90\n",
      "1408/1408 [==============================] - 0s - loss: 0.0014 - acc: 7.1023e-04 - val_loss: 0.0028 - val_acc: 0.0000e+00\n",
      "Epoch 46/90\n",
      "1408/1408 [==============================] - 0s - loss: 0.0014 - acc: 7.1023e-04 - val_loss: 0.0028 - val_acc: 0.0000e+00\n",
      "Epoch 47/90\n",
      "1408/1408 [==============================] - 0s - loss: 0.0014 - acc: 7.1023e-04 - val_loss: 0.0027 - val_acc: 0.0000e+00\n",
      "Epoch 48/90\n",
      "1408/1408 [==============================] - 0s - loss: 0.0015 - acc: 7.1023e-04 - val_loss: 0.0027 - val_acc: 0.0000e+00\n",
      "Epoch 49/90\n",
      "1408/1408 [==============================] - 0s - loss: 0.0014 - acc: 7.1023e-04 - val_loss: 0.0027 - val_acc: 0.0000e+00\n",
      "Epoch 50/90\n",
      "1408/1408 [==============================] - 0s - loss: 0.0014 - acc: 7.1023e-04 - val_loss: 0.0027 - val_acc: 0.0000e+00\n",
      "Epoch 51/90\n",
      "1408/1408 [==============================] - 0s - loss: 0.0015 - acc: 7.1023e-04 - val_loss: 0.0027 - val_acc: 0.0000e+00\n",
      "Epoch 52/90\n",
      "1408/1408 [==============================] - 0s - loss: 0.0014 - acc: 7.1023e-04 - val_loss: 0.0026 - val_acc: 0.0000e+00\n",
      "Epoch 53/90\n",
      "1408/1408 [==============================] - 0s - loss: 0.0014 - acc: 7.1023e-04 - val_loss: 0.0026 - val_acc: 0.0000e+00\n",
      "Epoch 54/90\n",
      "1408/1408 [==============================] - 0s - loss: 0.0014 - acc: 7.1023e-04 - val_loss: 0.0026 - val_acc: 0.0000e+00\n",
      "Epoch 55/90\n",
      "1408/1408 [==============================] - 0s - loss: 0.0013 - acc: 7.1023e-04 - val_loss: 0.0026 - val_acc: 0.0000e+00\n",
      "Epoch 56/90\n",
      "1408/1408 [==============================] - 0s - loss: 0.0013 - acc: 7.1023e-04 - val_loss: 0.0026 - val_acc: 0.0000e+00\n",
      "Epoch 57/90\n",
      "1408/1408 [==============================] - 0s - loss: 0.0013 - acc: 7.1023e-04 - val_loss: 0.0026 - val_acc: 0.0000e+00\n",
      "Epoch 58/90\n",
      "1408/1408 [==============================] - 0s - loss: 0.0013 - acc: 7.1023e-04 - val_loss: 0.0027 - val_acc: 0.0000e+00\n",
      "Epoch 59/90\n",
      "1408/1408 [==============================] - 0s - loss: 0.0014 - acc: 7.1023e-04 - val_loss: 0.0025 - val_acc: 0.0000e+00\n",
      "Epoch 60/90\n",
      "1408/1408 [==============================] - 0s - loss: 0.0013 - acc: 7.1023e-04 - val_loss: 0.0025 - val_acc: 0.0000e+00\n",
      "Epoch 61/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1408/1408 [==============================] - 0s - loss: 0.0014 - acc: 7.1023e-04 - val_loss: 0.0030 - val_acc: 0.0000e+00\n",
      "Epoch 62/90\n",
      "1408/1408 [==============================] - 0s - loss: 0.0014 - acc: 7.1023e-04 - val_loss: 0.0025 - val_acc: 0.0000e+00\n",
      "Epoch 63/90\n",
      "1408/1408 [==============================] - 0s - loss: 0.0013 - acc: 7.1023e-04 - val_loss: 0.0024 - val_acc: 0.0000e+00\n",
      "Epoch 64/90\n",
      "1408/1408 [==============================] - 0s - loss: 0.0013 - acc: 7.1023e-04 - val_loss: 0.0025 - val_acc: 0.0000e+00\n",
      "Epoch 65/90\n",
      "1408/1408 [==============================] - 0s - loss: 0.0014 - acc: 7.1023e-04 - val_loss: 0.0024 - val_acc: 0.0000e+00\n",
      "Epoch 66/90\n",
      "1408/1408 [==============================] - 0s - loss: 0.0013 - acc: 7.1023e-04 - val_loss: 0.0024 - val_acc: 0.0000e+00\n",
      "Epoch 67/90\n",
      "1408/1408 [==============================] - 0s - loss: 0.0012 - acc: 7.1023e-04 - val_loss: 0.0024 - val_acc: 0.0000e+00\n",
      "Epoch 68/90\n",
      "1408/1408 [==============================] - 0s - loss: 0.0013 - acc: 7.1023e-04 - val_loss: 0.0023 - val_acc: 0.0000e+00\n",
      "Epoch 69/90\n",
      "1408/1408 [==============================] - 0s - loss: 0.0012 - acc: 7.1023e-04 - val_loss: 0.0024 - val_acc: 0.0000e+00\n",
      "Epoch 70/90\n",
      "1408/1408 [==============================] - 0s - loss: 0.0012 - acc: 7.1023e-04 - val_loss: 0.0023 - val_acc: 0.0000e+00\n",
      "Epoch 71/90\n",
      "1408/1408 [==============================] - 0s - loss: 0.0013 - acc: 7.1023e-04 - val_loss: 0.0023 - val_acc: 0.0000e+00\n",
      "Epoch 72/90\n",
      "1408/1408 [==============================] - 0s - loss: 0.0013 - acc: 7.1023e-04 - val_loss: 0.0024 - val_acc: 0.0000e+00\n",
      "Epoch 73/90\n",
      "1408/1408 [==============================] - 0s - loss: 0.0012 - acc: 7.1023e-04 - val_loss: 0.0023 - val_acc: 0.0000e+00\n",
      "Epoch 74/90\n",
      "1408/1408 [==============================] - 0s - loss: 0.0012 - acc: 7.1023e-04 - val_loss: 0.0023 - val_acc: 0.0000e+00\n",
      "Epoch 75/90\n",
      "1408/1408 [==============================] - 0s - loss: 0.0012 - acc: 7.1023e-04 - val_loss: 0.0022 - val_acc: 0.0000e+00\n",
      "Epoch 76/90\n",
      "1408/1408 [==============================] - 0s - loss: 0.0013 - acc: 7.1023e-04 - val_loss: 0.0023 - val_acc: 0.0000e+00\n",
      "Epoch 77/90\n",
      "1408/1408 [==============================] - 0s - loss: 0.0013 - acc: 7.1023e-04 - val_loss: 0.0023 - val_acc: 0.0000e+00\n",
      "Epoch 78/90\n",
      "1408/1408 [==============================] - 0s - loss: 0.0012 - acc: 7.1023e-04 - val_loss: 0.0022 - val_acc: 0.0000e+00\n",
      "Epoch 79/90\n",
      "1408/1408 [==============================] - 0s - loss: 0.0012 - acc: 7.1023e-04 - val_loss: 0.0021 - val_acc: 0.0000e+00\n",
      "Epoch 80/90\n",
      "1408/1408 [==============================] - 0s - loss: 0.0012 - acc: 7.1023e-04 - val_loss: 0.0021 - val_acc: 0.0000e+00\n",
      "Epoch 81/90\n",
      "1408/1408 [==============================] - 0s - loss: 0.0011 - acc: 7.1023e-04 - val_loss: 0.0023 - val_acc: 0.0000e+00\n",
      "Epoch 82/90\n",
      "1408/1408 [==============================] - 0s - loss: 0.0012 - acc: 7.1023e-04 - val_loss: 0.0022 - val_acc: 0.0000e+00\n",
      "Epoch 83/90\n",
      "1408/1408 [==============================] - 0s - loss: 0.0012 - acc: 7.1023e-04 - val_loss: 0.0021 - val_acc: 0.0000e+00\n",
      "Epoch 84/90\n",
      "1408/1408 [==============================] - 0s - loss: 0.0012 - acc: 7.1023e-04 - val_loss: 0.0021 - val_acc: 0.0000e+00\n",
      "Epoch 85/90\n",
      "1408/1408 [==============================] - 0s - loss: 0.0011 - acc: 7.1023e-04 - val_loss: 0.0022 - val_acc: 0.0000e+00\n",
      "Epoch 86/90\n",
      "1408/1408 [==============================] - 0s - loss: 0.0013 - acc: 7.1023e-04 - val_loss: 0.0021 - val_acc: 0.0000e+00\n",
      "Epoch 87/90\n",
      "1408/1408 [==============================] - 0s - loss: 0.0012 - acc: 7.1023e-04 - val_loss: 0.0021 - val_acc: 0.0000e+00\n",
      "Epoch 88/90\n",
      "1408/1408 [==============================] - 0s - loss: 0.0012 - acc: 7.1023e-04 - val_loss: 0.0021 - val_acc: 0.0000e+00\n",
      "Epoch 89/90\n",
      "1408/1408 [==============================] - 0s - loss: 0.0012 - acc: 7.1023e-04 - val_loss: 0.0020 - val_acc: 0.0000e+00\n",
      "Epoch 90/90\n",
      "1408/1408 [==============================] - 0s - loss: 0.0013 - acc: 7.1023e-04 - val_loss: 0.0021 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f7b80133350>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train,batch_size=512,epochs=90,validation_split=0.1,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model_ebay.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pandas.read_csv(\"../nyse/prices-split-adjusted.csv\", index_col = 0)\n",
    "df = df[df.symbol == 'EBAY']\n",
    "df[\"adj close\"] = df.close # Moving close to the last column\n",
    "df.drop(['close'], 1, inplace=True) # Moving close to the last column\n",
    "df.drop(['symbol'],1,inplace=True)\n",
    "\n",
    "# Bug fixed at here, please update the denormalize function to this one\n",
    "def denormalize(df, normalized_value): \n",
    "    df = df['adj close'].values.reshape(-1,1)\n",
    "    normalized_value = normalized_value.reshape(-1,1)\n",
    "    \n",
    "    #return df.shape, p.shape\n",
    "    min_max_scaler = preprocessing.MinMaxScaler()\n",
    "    a = min_max_scaler.fit_transform(df)\n",
    "    new = min_max_scaler.inverse_transform(normalized_value)\n",
    "    return new\n",
    "\n",
    "newp = denormalize(df, p)\n",
    "newy_test = denormalize(df, y_test)\n",
    "# newp = p\n",
    "# newy_test = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f7a5020ef10>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7a502a2e10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(newp,color='red', label='Prediction')\n",
    "plt.plot(newy_test,color='blue', label='Actual')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_score(model, X_train, y_train, X_test, y_test):\n",
    "    trainScore = model.evaluate(X_train, y_train, verbose=0)\n",
    "    print('Train Score: %.5f MSE (%.2f RMSE)' % (trainScore[0], math.sqrt(trainScore[0])))\n",
    "\n",
    "    testScore = model.evaluate(X_test, y_test, verbose=0)\n",
    "    print('Test Score: %.5f MSE (%.2f RMSE)' % (testScore[0], math.sqrt(testScore[0])))\n",
    "    return trainScore[0], testScore[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score: 0.00089 MSE (0.03 RMSE)\n",
      "Test Score: 0.00288 MSE (0.05 RMSE)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.00088849090827858085, 0.0028790062007055372)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_score(model, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
